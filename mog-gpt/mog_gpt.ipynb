{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQ8iLMWDXNA_",
        "outputId": "322cbdb6-9b07-4bb7-9ae2-3c32e5563963"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import mmap\n",
        "import random\n",
        "import pickle\n",
        "import argparse\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "batch_size = 32\n",
        "block_size = 128\n",
        "max_iters = 3000\n",
        "learning_rate = 3e-4\n",
        "eval_iters = 50\n",
        "n_embd = 384\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.2\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kL0c7lLCXjA_",
        "outputId": "95de5175-46d9-4383-bfc4-c95fd3f2dc83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['\\n', ' ', '!', '(', ')', ',', '-', '.', '0', '1', '3', '4', '5', '6', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'ś', '—', '’', '“', '”', '•']\n"
          ]
        }
      ],
      "source": [
        "with open('text.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "chars = sorted(set(text))\n",
        "print(chars)\n",
        "vocab_size = len(chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "htTKteuWYZG9"
      },
      "outputs": [],
      "source": [
        "string_to_int = { ch:i for i,ch in enumerate(chars) }\n",
        "int_to_string = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [string_to_int[c] for c in s]\n",
        "decode = lambda l: ''.join([int_to_string[i] for i in l])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1d_PSiOq1Hg",
        "outputId": "25d413b3-0727-423d-a155-e60ad1612fad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "39629"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fdxKteFBYauu"
      },
      "outputs": [],
      "source": [
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.8*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "def get_batch(split):\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "t3dQXrTfYfNW"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_T8l3GkYz0p"
      },
      "outputs": [],
      "source": [
        "class Head(nn.Module):\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)\n",
        "        q = self.query(x)\n",
        "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        wei = self.dropout(wei)\n",
        "        v = self.value(x)\n",
        "        out = wei @ v\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1) # (B, T, F) -> (B, T, [h1, h1, h1, h1, h2, h2, h2, h2, h3, h3, h3, h3])\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.sa(x)\n",
        "        x = self.ln1(x + y)\n",
        "        y = self.ffwd(x)\n",
        "        x = self.ln2(x + y)\n",
        "        return x\n",
        "\n",
        "class MogGPT(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, index, targets=None):\n",
        "        B, T = index.shape\n",
        "        tok_emb = self.token_embedding_table(index)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device))\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, index, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            index_cond = index[:, -block_size:]\n",
        "            logits, loss = self.forward(index_cond)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            index_next = torch.multinomial(probs, num_samples=1)\n",
        "            index = torch.cat((index, index_next), dim=1)\n",
        "        return index\n",
        "\n",
        "model = MogGPT(vocab_size)\n",
        "m = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qkqn0mq5Y1YC",
        "outputId": "2fbbf57b-3413-4d62-cf01-1be8516cb1da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step: 0, train loss: 2.476, val loss: 2.494\n",
            "step: 50, train loss: 2.435, val loss: 2.455\n",
            "step: 100, train loss: 2.400, val loss: 2.440\n",
            "step: 150, train loss: 2.306, val loss: 2.347\n",
            "step: 200, train loss: 2.131, val loss: 2.186\n",
            "step: 250, train loss: 2.006, val loss: 2.098\n",
            "step: 300, train loss: 1.884, val loss: 2.025\n",
            "step: 350, train loss: 1.790, val loss: 1.957\n",
            "step: 400, train loss: 1.704, val loss: 1.894\n",
            "step: 450, train loss: 1.632, val loss: 1.867\n",
            "step: 500, train loss: 1.540, val loss: 1.830\n",
            "step: 550, train loss: 1.459, val loss: 1.815\n",
            "step: 600, train loss: 1.385, val loss: 1.791\n",
            "step: 650, train loss: 1.321, val loss: 1.804\n",
            "step: 700, train loss: 1.240, val loss: 1.797\n",
            "step: 750, train loss: 1.162, val loss: 1.794\n",
            "step: 800, train loss: 1.108, val loss: 1.833\n",
            "step: 850, train loss: 1.030, val loss: 1.854\n",
            "step: 900, train loss: 0.951, val loss: 1.849\n",
            "step: 950, train loss: 0.883, val loss: 1.894\n",
            "step: 1000, train loss: 0.820, val loss: 1.936\n",
            "step: 1050, train loss: 0.750, val loss: 1.962\n",
            "step: 1100, train loss: 0.706, val loss: 2.014\n",
            "step: 1150, train loss: 0.633, val loss: 2.058\n",
            "step: 1200, train loss: 0.591, val loss: 2.118\n",
            "step: 1250, train loss: 0.533, val loss: 2.129\n",
            "step: 1300, train loss: 0.474, val loss: 2.213\n",
            "step: 1350, train loss: 0.437, val loss: 2.262\n",
            "step: 1400, train loss: 0.398, val loss: 2.312\n",
            "step: 1450, train loss: 0.360, val loss: 2.354\n",
            "step: 1500, train loss: 0.328, val loss: 2.387\n",
            "step: 1550, train loss: 0.294, val loss: 2.464\n",
            "step: 1600, train loss: 0.269, val loss: 2.551\n",
            "step: 1650, train loss: 0.246, val loss: 2.609\n",
            "step: 1700, train loss: 0.228, val loss: 2.598\n",
            "step: 1750, train loss: 0.211, val loss: 2.670\n",
            "step: 1800, train loss: 0.196, val loss: 2.710\n",
            "step: 1850, train loss: 0.183, val loss: 2.793\n",
            "step: 1900, train loss: 0.175, val loss: 2.883\n",
            "step: 1950, train loss: 0.166, val loss: 2.890\n",
            "step: 2000, train loss: 0.155, val loss: 2.932\n",
            "step: 2050, train loss: 0.147, val loss: 2.979\n",
            "step: 2100, train loss: 0.144, val loss: 3.047\n",
            "step: 2150, train loss: 0.138, val loss: 3.051\n",
            "step: 2200, train loss: 0.132, val loss: 3.088\n",
            "step: 2250, train loss: 0.128, val loss: 3.137\n",
            "step: 2300, train loss: 0.123, val loss: 3.147\n",
            "step: 2350, train loss: 0.125, val loss: 3.199\n",
            "step: 2400, train loss: 0.120, val loss: 3.231\n",
            "step: 2450, train loss: 0.117, val loss: 3.284\n",
            "step: 2500, train loss: 0.115, val loss: 3.262\n",
            "step: 2550, train loss: 0.115, val loss: 3.302\n",
            "step: 2600, train loss: 0.111, val loss: 3.361\n",
            "step: 2650, train loss: 0.111, val loss: 3.356\n",
            "step: 2700, train loss: 0.111, val loss: 3.403\n",
            "step: 2750, train loss: 0.108, val loss: 3.411\n",
            "step: 2800, train loss: 0.106, val loss: 3.473\n",
            "step: 2850, train loss: 0.106, val loss: 3.455\n",
            "step: 2900, train loss: 0.104, val loss: 3.478\n",
            "step: 2950, train loss: 0.103, val loss: 3.467\n",
            "step: 3000, train loss: 0.102, val loss: 3.538\n",
            "step: 3050, train loss: 0.100, val loss: 3.508\n",
            "step: 3100, train loss: 0.101, val loss: 3.561\n",
            "step: 3150, train loss: 0.100, val loss: 3.612\n",
            "step: 3200, train loss: 0.098, val loss: 3.647\n",
            "step: 3250, train loss: 0.099, val loss: 3.636\n",
            "step: 3300, train loss: 0.097, val loss: 3.622\n",
            "step: 3350, train loss: 0.096, val loss: 3.695\n",
            "step: 3400, train loss: 0.097, val loss: 3.722\n",
            "step: 3450, train loss: 0.097, val loss: 3.748\n",
            "step: 3500, train loss: 0.096, val loss: 3.735\n",
            "step: 3550, train loss: 0.095, val loss: 3.747\n",
            "step: 3600, train loss: 0.093, val loss: 3.797\n",
            "step: 3650, train loss: 0.093, val loss: 3.826\n",
            "step: 3700, train loss: 0.093, val loss: 3.829\n",
            "step: 3750, train loss: 0.093, val loss: 3.835\n",
            "step: 3800, train loss: 0.092, val loss: 3.829\n",
            "step: 3850, train loss: 0.092, val loss: 3.841\n",
            "step: 3900, train loss: 0.093, val loss: 3.893\n",
            "step: 3950, train loss: 0.093, val loss: 3.916\n",
            "step: 4000, train loss: 0.091, val loss: 3.921\n",
            "step: 4050, train loss: 0.090, val loss: 3.940\n",
            "step: 4100, train loss: 0.091, val loss: 3.988\n",
            "step: 4150, train loss: 0.091, val loss: 3.942\n",
            "step: 4200, train loss: 0.089, val loss: 3.968\n",
            "step: 4250, train loss: 0.091, val loss: 3.976\n",
            "step: 4300, train loss: 0.090, val loss: 4.033\n",
            "step: 4350, train loss: 0.088, val loss: 3.996\n",
            "step: 4400, train loss: 0.088, val loss: 4.014\n",
            "step: 4450, train loss: 0.088, val loss: 4.047\n",
            "step: 4500, train loss: 0.087, val loss: 4.021\n",
            "step: 4550, train loss: 0.087, val loss: 4.065\n",
            "step: 4600, train loss: 0.087, val loss: 4.123\n",
            "step: 4650, train loss: 0.086, val loss: 4.071\n",
            "step: 4700, train loss: 0.086, val loss: 4.071\n",
            "step: 4750, train loss: 0.087, val loss: 4.162\n",
            "step: 4800, train loss: 0.087, val loss: 4.099\n",
            "step: 4850, train loss: 0.086, val loss: 4.191\n",
            "step: 4900, train loss: 0.086, val loss: 4.098\n",
            "step: 4950, train loss: 0.086, val loss: 4.207\n",
            "0.15469855070114136\n"
          ]
        }
      ],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(5000):\n",
        "    if iter % eval_iters == 0:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step: {iter}, train loss: {losses['train']:.3f}, val loss: {losses['val']:.3f}\")\n",
        "\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    logits, loss = model.forward(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwDuE-seY8qk",
        "outputId": "02cf5e3f-a0dd-4714-e948-34a9d55bcd9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Whenever you notice rising pressure and stress leveng in the\n",
            "armor, rerom a customer reasoning policies that\n",
            "meands overach ch ofraso guide. Your feeled to adeat the irrational will find ith a figure was how to\n",
            "get out of this trap, how to be truly rad to that their natural at onese of events.”\n",
            "Differences between Athenians were fine to state of Meloards\n",
            "such a rgue of s and the rat\n"
          ]
        }
      ],
      "source": [
        "prompt = 'Whenever you notice rising pressure'\n",
        "context = torch.tensor(encode(prompt), dtype=torch.long, device=device)\n",
        "generated_chars = decode(m.generate(context.unsqueeze(0), max_new_tokens=350)[0].tolist())\n",
        "print(generated_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rx-D8Rr2nQ9J"
      },
      "outputs": [],
      "source": [
        "torch.save(m.state_dict(), \"model_weights.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "4wuxF9jF3vdP"
      },
      "outputs": [],
      "source": [
        "torch.save(m, \"model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbHxV_oj3zjz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
